{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emcandrew/anaconda3/envs/tf_latest/lib/python3.7/site-packages/scanpy/api/__init__.py:7: FutureWarning: \n",
      "\n",
      "In a future version of Scanpy, `scanpy.api` will be removed.\n",
      "Simply use `import scanpy as sc` and `import scanpy.external as sce` instead.\n",
      "\n",
      "  FutureWarning,\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.5.1 anndata==0.7.3 umap==0.4.4 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.23.1 statsmodels==0.11.1 python-igraph==0.8.2 louvain==0.7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy.api as sc\n",
    "import anndata\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import sys\n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorboard\n",
    "from keras.layers import Dense, Flatten, Reshape\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from umap import UMAP\n",
    "import seaborn as sns \n",
    "\n",
    "sc.settings.verbosity = 3 \n",
    "sc.settings.set_figure_params(dpi=80)  # low dpi (dots per inch) yields small inline figures\n",
    "sc.logging.print_versions()\n",
    "\n",
    "\n",
    "learning_rate = 0.005\n",
    "learning_rate_g = 0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# open tensorboard and set log dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3368), started 4 days, 0:05:44 ago. (Use '!kill 3368' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9754bf2f69109dbe\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9754bf2f69109dbe\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_dir = \"./tmp/logs/\"\n",
    "summary_writer = tf.summary.create_file_writer(logdir=log_dir)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./tmp/logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in already preprocessed input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "exp_mat = pd.read_csv(\"Gan_input2.csv\", sep='\\t', index_col = 0)\n",
    "exp_mat = exp_mat.T\n",
    "\n",
    "input_matrix = np.genfromtxt('Gan_input2.csv', skip_header=1)\n",
    "\n",
    "input_matrix = input_matrix.T\n",
    "input_matrix.shape\n",
    "\n",
    "\n",
    "input_matrix = np.delete(input_matrix, (0), axis=0)\n",
    "\n",
    "scaler.fit(input_matrix)\n",
    "input_matrix = scaler.transform(input_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model input dimensions\n",
    "\n",
    "\n",
    "cell = (793,)\n",
    "z_dim = 100 # noise vector size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04862233, 0.0973451 , 0.09687525, 0.07856252, 0.0147812 ,\n",
       "       0.01920392, 0.81562851, 0.44044766, 0.06855113, 0.28822035,\n",
       "       0.02502037, 0.43199348, 0.11830732, 0.08039244, 0.0476922 ,\n",
       "       0.04408576, 0.08625219, 0.2066288 , 0.14781333, 0.27369769,\n",
       "       0.07839337, 0.01028991, 0.58214049, 0.37654752, 0.02902108,\n",
       "       0.01979388, 0.03205911, 0.13221802, 0.87988892, 0.06814237,\n",
       "       0.10142352, 0.35575929, 0.12843781, 0.11922874, 0.05723442,\n",
       "       0.03190849, 0.07722307, 0.00597578, 0.07536983, 0.0603617 ,\n",
       "       0.3104535 , 0.13179429, 0.20605584, 0.04396074, 0.36566019,\n",
       "       0.23292322, 0.78121021, 0.72915296, 0.76514923, 0.15905401,\n",
       "       0.22161928, 0.28123768, 0.13233827, 0.06387014, 0.11978799,\n",
       "       0.10004397, 0.11301476, 0.79455268, 0.11043198, 0.08118584,\n",
       "       0.30215932, 0.05081357, 0.08015451, 0.34057817, 0.14005516,\n",
       "       0.80641925, 0.51819116, 0.32599389, 0.09818237, 0.10035685,\n",
       "       0.02478997, 0.20499261, 0.03987337, 0.03708293, 0.20437391,\n",
       "       0.02401807, 0.17697187, 0.12053082, 0.17477627, 0.8702443 ,\n",
       "       0.0317369 , 0.42996537, 0.2186166 , 0.81527346, 0.09106277,\n",
       "       0.24566006, 0.01181727, 0.74392955, 0.14406289, 0.13200128,\n",
       "       0.17090062, 0.0175062 , 0.16526145, 0.00763985, 0.08924008,\n",
       "       0.22715292, 0.09952518, 0.03961152, 0.00964691, 0.24701151,\n",
       "       0.10538432, 0.02986989, 0.04680069, 0.07845059, 0.38268689,\n",
       "       0.87019392, 0.06431867, 0.33235055, 0.01694345, 0.01474914,\n",
       "       0.0721536 , 0.02828004, 0.38799399, 0.06998253, 0.13548304,\n",
       "       0.08854843, 0.18187403, 0.24376339, 0.01310006, 0.03457815,\n",
       "       0.04707735, 0.11923104, 0.05006707, 0.32874196, 0.32011163,\n",
       "       0.49629849, 0.01539685, 0.02614297, 0.07313003, 0.50113235,\n",
       "       0.11273239, 0.06741039, 0.00524557, 0.0248605 , 0.25819935,\n",
       "       0.02831927, 0.03693351, 0.09648658, 0.07231307, 0.03068137,\n",
       "       0.28233926, 0.01647737, 0.1432044 , 0.04316139, 0.03046016,\n",
       "       0.11448609, 0.00767032, 0.01780824, 0.01104628, 0.04569007,\n",
       "       0.11036054, 0.15127766, 0.16747119, 0.06409928, 0.15530384,\n",
       "       0.36621657, 0.47862692, 0.01404892, 0.0401478 , 0.08320367,\n",
       "       0.07803963, 0.09013294, 0.13811547, 0.08792324, 0.14605418,\n",
       "       0.09884375, 0.08060633, 0.05714162, 0.17572368, 0.03202198,\n",
       "       0.04587473, 0.04328914, 0.04038029, 0.04264126, 0.02597129,\n",
       "       0.19214158, 0.1286606 , 0.07714196, 0.30641487, 0.01311541,\n",
       "       0.04565662, 0.34265005, 0.07481352, 0.01617104, 0.03242438,\n",
       "       0.03238837, 0.04071964, 0.39617337, 0.01088237, 0.13991404,\n",
       "       0.13230655, 0.03045398, 0.20975095, 0.04916137, 0.89693816,\n",
       "       0.05585975, 0.05921101, 0.11152467, 0.01169035, 0.28349378,\n",
       "       0.4845236 , 0.10544598, 0.05933972, 0.1114242 , 0.08828628,\n",
       "       0.11757691, 0.1375603 , 0.07342357, 0.32315047, 0.04382872,\n",
       "       0.02791862, 0.03174679, 0.02718481, 0.16411774, 0.65371064,\n",
       "       0.0911305 , 0.14060274, 0.19533499, 0.1577928 , 0.19195091,\n",
       "       0.07176671, 0.02451207, 0.07558087, 0.22613429, 0.02695463,\n",
       "       0.2306143 , 0.10176233, 0.03678163, 0.54946641, 0.03962133,\n",
       "       0.0370408 , 0.1827497 , 0.1235368 , 0.39833482, 0.15666406,\n",
       "       0.0562015 , 0.29793962, 0.48491145, 0.00635299, 0.93783932,\n",
       "       0.02228099, 0.8632942 , 0.09796422, 0.00826021, 0.01534346,\n",
       "       0.02668775, 0.26852977, 0.75238552, 0.79508884, 0.0910952 ,\n",
       "       0.1635415 , 0.53679263, 0.02643292, 0.20820067, 0.0363668 ,\n",
       "       0.02631911, 0.16674752, 0.0733605 , 0.65332713, 0.1283596 ,\n",
       "       0.06409504, 0.86311577, 0.06945546, 0.0153515 , 0.30280063,\n",
       "       0.85672304, 0.05898858, 0.34082696, 0.42543819, 0.06159691,\n",
       "       0.0925891 , 0.22133888, 0.069216  , 0.11590607, 0.02621608,\n",
       "       0.03491346, 0.05345307, 0.01204924, 0.03676305, 0.02233626,\n",
       "       0.08791831, 0.28375205, 0.24119933, 0.77934328, 0.12029144,\n",
       "       0.80206643, 0.16895602, 0.50503494, 0.34984369, 0.38193331,\n",
       "       0.40952549, 0.11951759, 0.81417414, 0.47832359, 0.26928087,\n",
       "       0.03502285, 0.05533755, 0.05601072, 0.08338738, 0.08016954,\n",
       "       0.04500571, 0.88419448, 0.13306694, 0.06190253, 0.90188202,\n",
       "       0.20755773, 0.08571837, 0.01209672, 0.04670307, 0.11970975,\n",
       "       0.09560028, 0.13076293, 0.18174925, 0.10163501, 0.11718783,\n",
       "       0.03056298, 0.23464269, 0.07750073, 0.06944822, 0.0098572 ,\n",
       "       0.24023802, 0.24319336, 0.18642391, 0.69903714, 0.04497298,\n",
       "       0.05820432, 0.1608696 , 0.10845912, 0.3132921 , 0.05603702,\n",
       "       0.0715663 , 0.7344872 , 0.89307988, 0.90360224, 0.02971361,\n",
       "       0.02514468, 0.23831777, 0.03019854, 0.06753052, 0.02849628,\n",
       "       0.01892282, 0.02712817, 0.66641237, 0.04770566, 0.01950963,\n",
       "       0.05504857, 0.04196599, 0.2104901 , 0.0386257 , 0.02276126,\n",
       "       0.02899049, 0.14894488, 0.55143224, 0.05365016, 0.34124443,\n",
       "       0.18171563, 0.06573472, 0.00862957, 0.04170828, 0.06605384,\n",
       "       0.05789821, 0.08900474, 0.51949744, 0.03104171, 0.10391815,\n",
       "       0.03852369, 0.37580238, 0.87537093, 0.88883293, 0.0469303 ,\n",
       "       0.56121886, 0.15264966, 0.21441377, 0.13996429, 0.1573233 ,\n",
       "       0.03008629, 0.0916555 , 0.0478247 , 0.15804504, 0.01179282,\n",
       "       0.07830722, 0.14723525, 0.02126187, 0.18283392, 0.10747235,\n",
       "       0.03713641, 0.1284588 , 0.03525625, 0.04483819, 0.03856322,\n",
       "       0.13421992, 0.06864557, 0.00829256, 0.09618524, 0.87906991,\n",
       "       0.04020118, 0.05807477, 0.41344831, 0.02340907, 0.55678617,\n",
       "       0.04030094, 0.06701694, 0.19359477, 0.10417312, 0.14510466,\n",
       "       0.18179069, 0.05378756, 0.12333347, 0.02095896, 0.06828263,\n",
       "       0.03045562, 0.0194732 , 0.16614529, 0.08546482, 0.0657515 ,\n",
       "       0.12173024, 0.09893305, 0.14486145, 0.78687676, 0.0505084 ,\n",
       "       0.07321061, 0.87020357, 0.16279463, 0.51620783, 0.12699183,\n",
       "       0.17462909, 0.10474367, 0.0103539 , 0.04141943, 0.07063712,\n",
       "       0.14563799, 0.02480982, 0.03371356, 0.05820716, 0.77943362,\n",
       "       0.03154214, 0.01139285, 0.05410542, 0.07212877, 0.44582621,\n",
       "       0.27236524, 0.04076826, 0.26788647, 0.22834212, 0.04185531,\n",
       "       0.22040309, 0.03032383, 0.06975933, 0.88484763, 0.16174827,\n",
       "       0.3443889 , 0.58367941, 0.79546751, 0.53267127, 0.14275511,\n",
       "       0.27159873, 0.05100862, 0.12841635, 0.1170197 , 0.03444561,\n",
       "       0.0504391 , 0.30158134, 0.03067244, 0.09658423, 0.03572801,\n",
       "       0.87126209, 0.23490028, 0.15937576, 0.0876668 , 0.02100021,\n",
       "       0.81206942, 0.07710445, 0.00923954, 0.13091711, 0.08459982,\n",
       "       0.21056933, 0.03115139, 0.05928991, 0.03660323, 0.41188939,\n",
       "       0.0497217 , 0.02895053, 0.25117969, 0.01739618, 0.05061998,\n",
       "       0.11432181, 0.11626502, 0.08880519, 0.30902701, 0.10329432,\n",
       "       0.02063326, 0.08004027, 0.17401707, 0.14127563, 0.22805403,\n",
       "       0.06296252, 0.05415111, 0.78278563, 0.01268182, 0.18529407,\n",
       "       0.12660819, 0.04733276, 0.02667089, 0.02748174, 0.02363706,\n",
       "       0.03346064, 0.45975501, 0.40092289, 0.13423218, 0.11325082,\n",
       "       0.08614091, 0.06867847, 0.02837211, 0.08148123, 0.01350766,\n",
       "       0.02058436, 0.02996932, 0.52499282, 0.07663219, 0.06277472,\n",
       "       0.01972409, 0.01348278, 0.12661029, 0.0899033 , 0.8540224 ,\n",
       "       0.01183549, 0.27275377, 0.0406923 , 0.35698669, 0.00704775,\n",
       "       0.36179629, 0.02798321, 0.04669255, 0.10103835, 0.04703052,\n",
       "       0.84277346, 0.01982407, 0.09739824, 0.01725781, 0.01552236,\n",
       "       0.30574051, 0.05600681, 0.0754408 , 0.05230926, 0.08855258,\n",
       "       0.33409479, 0.14323951, 0.04240086, 0.3439892 , 0.04740561,\n",
       "       0.08330892, 0.05507568, 0.29709991, 0.07981218, 0.05163434,\n",
       "       0.84016409, 0.03347145, 0.82887674, 0.58703452, 0.04807835,\n",
       "       0.03499671, 0.23522501, 0.11763719, 0.23963736, 0.29624258,\n",
       "       0.06480394, 0.05841634, 0.05285551, 0.09699582, 0.50227734,\n",
       "       0.04158945, 0.19014286, 0.38613019, 0.10538011, 0.09682389,\n",
       "       0.14276207, 0.01384669, 0.14867605, 0.55709727, 0.02477761,\n",
       "       0.08233698, 0.25244716, 0.11439063, 0.15580858, 0.0621998 ,\n",
       "       0.01499391, 0.04789159, 0.80772722, 0.02344148, 0.05382874,\n",
       "       0.03958327, 0.09807164, 0.13770201, 0.1251913 , 0.1209971 ,\n",
       "       0.07076734, 0.06630439, 0.02232251, 0.23421363, 0.08457657,\n",
       "       0.20707589, 0.02958789, 0.063538  , 0.00852074, 0.24075942,\n",
       "       0.11397976, 0.04730304, 0.13107033, 0.09006202, 0.75821336,\n",
       "       0.23452756, 0.86574606, 0.13432116, 0.17995099, 0.07129344,\n",
       "       0.01696089, 0.00756154, 0.05720664, 0.05008776, 0.04061747,\n",
       "       0.08278808, 0.76916121, 0.10898569, 0.06102089, 0.0742064 ,\n",
       "       0.13042293, 0.03855525, 0.00999097, 0.37999316, 0.45786655,\n",
       "       0.55939267, 0.09264706, 0.05754373, 0.11525307, 0.15413807,\n",
       "       0.23336411, 0.06156864, 0.01565872, 0.02670488, 0.08911424,\n",
       "       0.03889257, 0.11006524, 0.02717609, 0.02718242, 0.19668299,\n",
       "       0.04570628, 0.04093975, 0.33805957, 0.1502067 , 0.05092306,\n",
       "       0.02409438, 0.01245629, 0.1311371 , 0.01485764, 0.08105109,\n",
       "       0.27635559, 0.26867737, 0.05239248, 0.13701686, 0.06923513,\n",
       "       0.16000964, 0.28867276, 0.09940266, 0.04774281, 0.1919751 ,\n",
       "       0.11922393, 0.03006358, 0.03501675, 0.13252605, 0.04607294,\n",
       "       0.0927816 , 0.04222943, 0.17770826, 0.35138526, 0.01679417,\n",
       "       0.79492155, 0.86232797, 0.08277824, 0.16338696, 0.31632056,\n",
       "       0.0981369 , 0.5428567 , 0.30141665, 0.02586858, 0.07256626,\n",
       "       0.12332953, 0.02620034, 0.80049336, 0.01667605, 0.10716784,\n",
       "       0.03437339, 0.06818839, 0.11606193, 0.0417708 , 0.04848865,\n",
       "       0.0721157 , 0.02503205, 0.11824596, 0.17234864, 0.5391347 ,\n",
       "       0.53250144, 0.13935381, 0.11116375, 0.08841403, 0.10126957,\n",
       "       0.05667118, 0.05157307, 0.30809313, 0.09088408, 0.045585  ,\n",
       "       0.07542597, 0.01161022, 0.04986615, 0.49917166, 0.40872175,\n",
       "       0.10189665, 0.1093844 , 0.8466954 , 0.56047762, 0.08403079,\n",
       "       0.10112247, 0.0640985 , 0.05959224, 0.06603313, 0.06607982,\n",
       "       0.0549681 , 0.04140049, 0.15245972, 0.0138534 , 0.7610835 ,\n",
       "       0.01952122, 0.05954734, 0.00809178, 0.03575616, 0.01704386,\n",
       "       0.0555778 , 0.00345137, 0.92823047, 0.85420603, 0.11771749,\n",
       "       0.1044552 , 0.49088422, 0.06846935, 0.05385633, 0.13820653,\n",
       "       0.01695538, 0.17722745, 0.12257554, 0.12720648, 0.01680339,\n",
       "       0.49508186, 0.02247887, 0.45975914, 0.080115  , 0.01206859,\n",
       "       0.01393053, 0.01713795, 0.01881508, 0.02282116, 0.0474976 ,\n",
       "       0.00554121, 0.05991801, 0.04303488, 0.00657506, 0.05298392,\n",
       "       0.01283883, 0.06339511, 0.19993562, 0.21890217, 0.05470704,\n",
       "       0.10525279, 0.08503912, 0.08013554, 0.57052091, 0.32155   ,\n",
       "       0.01636277, 0.05233768, 0.14478898, 0.09007606, 0.12287535,\n",
       "       0.02091841, 0.29896962, 0.07320233, 0.03393024, 0.91381128,\n",
       "       0.11416367, 0.14821127, 0.15870969, 0.09203228, 0.02314246,\n",
       "       0.08209233, 0.1290154 , 0.06907798])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator as a function. Returns the generator network model.\n",
    "\n",
    "def build_generator(cell, z_dim) :\n",
    "  \n",
    "  # Defines the model\n",
    "  model = Sequential()\n",
    "\n",
    "  # Adds a dense layer of 64 neurons with input_dim equal to z_dim\n",
    "  model.add(Dense(450, input_dim = z_dim))\n",
    "\n",
    "  # Apply Leaky ReLU activaion function \n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "  # Adds another fully connected layer - output layer \n",
    "  model.add(Dense(793))\n",
    "\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(Reshape(cell))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Discrimator network\n",
    "\n",
    "def build_critic(cell) :\n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Dense(200, input_shape = cell))\n",
    "\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(Dense(200))\n",
    "\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(Dense(1))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wasserstein loss function\n",
    "\n",
    "def wasserstein( y_true, y_pred):\n",
    "    wloss = -keras.backend.mean(y_true * y_pred)\n",
    "    return wloss\n",
    "\n",
    "# \n",
    "def build_gan(generator, critic) :\n",
    "\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(generator)\n",
    "  model.add(critic)\n",
    "\n",
    "  return model\n",
    "\n",
    "critic = build_critic(cell)\n",
    "critic.compile(loss = wasserstein,\n",
    "                    optimizer = keras.optimizers.RMSprop(learning_rate = 0.00005),\n",
    "                    metrics = ['accuracy'])\n",
    "\n",
    "generator = build_generator(cell, z_dim)\n",
    "critic.trainable = False\n",
    "\n",
    "gan = build_gan(generator, critic)\n",
    "gan.compile(loss= wasserstein, optimizer= keras.optimizers.RMSprop(learning_rate =  0.00005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cells(number_cells) :\n",
    "    \n",
    "    # Draws from random normal.\n",
    "    noise = np.random.normal(0, 1, (1, z_dim))\n",
    "    \n",
    "    # predcts using enerator network.\n",
    "    gen_cell = generator.predict(noise)\n",
    "    \n",
    "    # Transform back from MinMax scaling between -1 and 1 (necesscary for tanh activation function) \n",
    "    gen_cell = scaler.inverse_transform(gen_cell)\n",
    "\n",
    "\n",
    "   # Repeat of above procedure inside a loop. \n",
    "    for cell in range(num_cells -1 ):\n",
    "    \n",
    "            noise = np.random.normal(0, 1, (1, z_dim))\n",
    "    \n",
    "            gen_cells_tmp = generator.predict(noise)\n",
    "    \n",
    "            gen_cells_tmp = scaler.inverse_transform(gen_cells_tmp)\n",
    "        \n",
    "          #  Appends subsequent generated cells to form an array of generated cells\n",
    "            gen_cell = np.append(gen_cell, gen_cells_tmp, axis=0)\n",
    "    \n",
    "    # Converts array to matrice object\n",
    "    gen_cell = np.asmatrix(gen_cell)\n",
    "    \n",
    "    # converts matrice to pandas dataframe\n",
    "    gen_cell = pd.DataFrame(gen_cell)\n",
    "    \n",
    "    # Loop to create cell names (theres deinitely a better way to do this)\n",
    "    cell_names = []\n",
    "    for i in range(num_cells ):\n",
    "        cell_names.append(\"cell-{}\".format(i +1))\n",
    "        \n",
    "        \n",
    "    # Creates final dataframe with gene names and cell IDs\n",
    "    gen_cell = pd.DataFrame(data=gen_cell.values, columns=exp_mat.columns, index = cell_names)\n",
    "    \n",
    "    return gen_cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "iteration_checkpoints = []\n",
    "Generated_cells = []\n",
    "\n",
    "\n",
    "\n",
    "def train_critic(X_train, batch_size, clip_threshold):\n",
    "\n",
    "    X_train =  input_matrix\n",
    "\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = -np.ones((batch_size, 1))\n",
    "    \n",
    "    # Train on real data\n",
    "    idx = np.random.randint(X_train.shape[0], size = batch_size)\n",
    "    real_cell = X_train[idx]\n",
    "    c_loss_real = critic.train_on_batch(real_cell, valid)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train on generated data\n",
    "    noise = np.random.normal(0,1, (batch_size, z_dim))\n",
    "    fake_cell = generator.predict(noise)\n",
    "    c_loss_fake = critic.train_on_batch(fake_cell, fake)\n",
    "    \n",
    "    c_loss = 0.5 * np.add(c_loss_fake, c_loss_real)\n",
    "    \n",
    "      \n",
    "    for l in critic.layers:\n",
    "        weights = l.get_weights()\n",
    "        weights = [np.clip(w, -clip_threshold, clip_threshold) for w in weights]\n",
    "        l.set_weights(weights)\n",
    "    \n",
    "    return c_loss\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(batch_size) :\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    \n",
    "    noise = np.random.normal(0,1, (batch_size, z_dim))\n",
    "    g_loss = gan.train_on_batch(noise, valid)\n",
    "    return g_loss\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emcandrew/anaconda3/envs/tf_latest/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [D loss: 1.001285] [G loss: 0.974836]\n",
      "2000 [D loss: 1.000520] [G loss: 0.994503]\n",
      "3000 [D loss: 1.001611] [G loss: 0.983599]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emcandrew/anaconda3/envs/tf_latest/lib/python3.7/site-packages/keras/engine/training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6b01c5974a65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-fd98155b7acc>\u001b[0m in \u001b[0;36mtrain_critic\u001b[0;34m(X_train, batch_size, clip_threshold)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfake_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mc_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_loss_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_loss_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_latest/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_latest/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3784\u001b[0m               'You must feed a value for placeholder %s' % (tensor,))\n\u001b[1;32m   3785\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3786\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3787\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3788\u001b[0m         \u001b[0;31m# Temporary workaround due to `convert_to_tensor` not casting floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_latest/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1281\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_latest/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1348\u001b[0m           \u001b[0;34m\"%sConversion function %r for type %s returned non-Tensor: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m           (_error_prefix(name), conversion_func, base_type, ret))\n\u001b[0;32m-> 1350\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m       raise RuntimeError(\n\u001b[1;32m   1352\u001b[0m           \u001b[0;34m\"%sConversion function %r for type %s returned incompatible \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_latest/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;31m# Note: using the intern table directly here as this is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;31m# performance-sensitive in some models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datatype_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# running the model\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Setting hyper parameters\n",
    "epochs = 30000\n",
    "batch_size = 32\n",
    "sample_interval = 1000\n",
    "generate_cells_every = 3000\n",
    "num_cells = 2000\n",
    "X_train = input_matrix\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(2):\n",
    "        c_loss = train_critic(X_train, batch_size= batch_size, clip_threshold = 0.01)\n",
    "    \n",
    "    g_loss = train_generator(batch_size)\n",
    "\n",
    "    if (epoch + 1) % sample_interval == 0: \n",
    "        iteration_checkpoints.append(epoch + 1)\n",
    "        losses.append((c_loss, g_loss))\n",
    "        print (\"%d [D loss: %f] [G loss: %f]\" % (epoch+1, 1 - sum(c_loss)/len(c_loss), 1 - g_loss))\n",
    "\n",
    "    if (epoch +1) % generate_cells_every == 0:\n",
    "        gen_cell = generate_cells(500)\n",
    "        Generated_cells.append(gen_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generated_cells[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = Generated_cells[4]\n",
    "#output.to_csv('gen_cells.csv', sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generated_cells[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in Generated_cells :\n",
    "    test = dataset\n",
    "    adata = sc.AnnData(test)\n",
    "    adata.X\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "    sc.tl.louvain(adata, resolution=1, key_added='louvain_r1')\n",
    "    sc.pl.umap(adata, color='louvain_r1')\n",
    "    sc.tl.rank_genes_groups(adata, 'louvain_r1', method='logreg')\n",
    "    sc.pl.rank_genes_groups(adata, n_genes=20)\n",
    "    result = adata.uns['rank_genes_groups']\n",
    "    groups = result['names'].dtype.names\n",
    "    pd.DataFrame({group + '_' + key[:1]: result[key][group]\n",
    "        for group in groups for key in ['names', 'scores']}).head(10)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
